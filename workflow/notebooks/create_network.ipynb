{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_dict(fn: str) -> dict:\n",
    "    \"\"\" Loads a pickle file and returns a dictionary \"\"\"\n",
    "    with open(fn, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_protein_id_from_gff_info(info: str) -> str:\n",
    "    \"\"\" Returns the protein_id from a gff info field \"\"\"\n",
    "    return dict(map(lambda x: x.split('='), info.split(';'))).get('locus_tag')\n",
    "\n",
    "def parse_merged_gff(fn: str) -> Generator[tuple[str], None, None]:\n",
    "    \"\"\" Parses a merged gff file and returns a generator of tuples \"\"\"\n",
    "\n",
    "    with open(fn) as f:\n",
    "        lines = map(str.strip, f)\n",
    "        remove_headers = filter(lambda x: not x.startswith('#'), lines)\n",
    "\n",
    "        while (line := next(remove_headers, None)):\n",
    "            contig, *_, info = line.split('\\t')\n",
    "            protein_id = get_protein_id_from_gff_info(info)\n",
    "            assembly, contig = contig.split('_')\n",
    "            yield (assembly, contig, protein_id)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmseqs_to_dict(fn: str) -> dict:\n",
    "    with open(fn, 'r', encoding='utf-8') as f:\n",
    "        return dict(map(lambda x: x.strip().split('\\t'), f))\n",
    "\n",
    "# cluster_assignments = pickle_to_dict('/home/hugo/projects/icetea/results/mmseqs/CLUSTERS_REPS_unique.pickle')\n",
    "cluster_assignments = mmseqs_to_dict('/home/hugo/projects/icetea/results/mmseqs/CLUSTERS_REPS_unique.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>assembly</th>\n",
       "      <th>contig</th>\n",
       "      <th>contig_edge_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CKDALPML_03566</td>\n",
       "      <td>LHMLBOEB_02289</td>\n",
       "      <td>1243621.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LHMLBOEB_02289</td>\n",
       "      <td>PEEGAIPP_04538</td>\n",
       "      <td>1243621.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEEGAIPP_04538</td>\n",
       "      <td>LGJOCDDL_01219</td>\n",
       "      <td>1243621.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGJOCDDL_01219</td>\n",
       "      <td>OGKIMEBI_00005</td>\n",
       "      <td>1243621.3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OGKIMEBI_00005</td>\n",
       "      <td>GCDOEBIL_03948</td>\n",
       "      <td>1243621.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505883</th>\n",
       "      <td>PFKGKOIO_03960</td>\n",
       "      <td>JOKGDMAP_04363</td>\n",
       "      <td>997338.3</td>\n",
       "      <td>99</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505884</th>\n",
       "      <td>JOKGDMAP_04363</td>\n",
       "      <td>LELPPPGI_04228</td>\n",
       "      <td>997338.3</td>\n",
       "      <td>99</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505885</th>\n",
       "      <td>LELPPPGI_04228</td>\n",
       "      <td>BHIIONFH_05865</td>\n",
       "      <td>997338.3</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505886</th>\n",
       "      <td>BHIIONFH_05865</td>\n",
       "      <td>GEOMEPHB_03958</td>\n",
       "      <td>997338.3</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505887</th>\n",
       "      <td>GEOMEPHB_03958</td>\n",
       "      <td>JADHFFOP_03557</td>\n",
       "      <td>997338.3</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505888 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source          target   assembly contig  contig_edge_position\n",
       "0       CKDALPML_03566  LHMLBOEB_02289  1243621.3      1                     1\n",
       "1       LHMLBOEB_02289  PEEGAIPP_04538  1243621.3      1                     2\n",
       "2       PEEGAIPP_04538  LGJOCDDL_01219  1243621.3      1                     3\n",
       "3       LGJOCDDL_01219  OGKIMEBI_00005  1243621.3      1                     4\n",
       "4       OGKIMEBI_00005  GCDOEBIL_03948  1243621.3      1                     5\n",
       "...                ...             ...        ...    ...                   ...\n",
       "505883  PFKGKOIO_03960  JOKGDMAP_04363   997338.3     99                    47\n",
       "505884  JOKGDMAP_04363  LELPPPGI_04228   997338.3     99                    48\n",
       "505885  LELPPPGI_04228  BHIIONFH_05865   997338.3     99                    49\n",
       "505886  BHIIONFH_05865  GEOMEPHB_03958   997338.3     99                    50\n",
       "505887  GEOMEPHB_03958  JADHFFOP_03557   997338.3     99                    51\n",
       "\n",
       "[505888 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_cds = parse_merged_gff('/home/hugo/projects/icetea/results/gff/all.cds.gff.sample.out')\n",
    "\n",
    "add_cluster_assignments = map(lambda x: (*x[:-1], cluster_assignments.get(x[-1])), all_cds)\n",
    "\n",
    "def get_edges(locus_tags: tuple) -> set:\n",
    "    edges = zip(locus_tags, locus_tags[1:])\n",
    "    remove_fragments = filter(lambda x: x[0] != x[1], edges)\n",
    "    remove_none = filter(all, remove_fragments)\n",
    "    add_on_contig_position = map(lambda x: (*x[-1], x[0]), enumerate(remove_none, start=1))\n",
    "    return tuple(add_on_contig_position)\n",
    "\n",
    "\n",
    "\n",
    "    # return series.apply(lambda x:  )\n",
    "\n",
    "cds_data = (\n",
    "    pd.DataFrame(\n",
    "        # islice(add_cluster_assignments, 1000),\n",
    "        add_cluster_assignments,\n",
    "        columns=['assembly', 'contig', 'cluster_id'],\n",
    "    )\n",
    "    .groupby(['assembly', 'contig'])\n",
    "    .agg(tuple)\n",
    "    .loc[lambda df_: df_.cluster_id.apply(len).gt(1)]\n",
    "    .rename(columns={'cluster_id': 'edge'})\n",
    "    .assign(\n",
    "        edge = lambda x: x.edge.apply(get_edges),\n",
    "    )\n",
    "    .explode('edge')\n",
    "    .assign(\n",
    "        source = lambda x: x.edge.apply(lambda x: x[0]),\n",
    "        target = lambda x: x.edge.apply(lambda x: x[1]),\n",
    "        contig_edge_position = lambda x: x.edge.apply(lambda x: x[2]),\n",
    "    )\n",
    "    .drop(columns='edge')\n",
    "    .reset_index()\n",
    "    .loc[:, ['source', 'target', 'assembly', 'contig', 'contig_edge_position']]\n",
    "    # .set_index(['source', 'target'])\n",
    "    # .agg(tuple, axis=1)\n",
    "    # .groupby(['source', 'target'])\n",
    "    # .agg(tuple)\n",
    ")\n",
    "\n",
    "cds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmseqs_to_dict(fn: str) -> dict:\n",
    "    with open(fn, 'r', encoding='utf-8') as f:\n",
    "        return dict(map(lambda x: x.strip().split('\\t'), f))\n",
    "    \n",
    "def get_edges(locus_tags: tuple) -> set:\n",
    "    edges = zip(locus_tags, locus_tags[1:])\n",
    "    remove_fragments = filter(lambda x: x[0] != x[1], edges)\n",
    "    remove_none = filter(all, remove_fragments)\n",
    "    add_on_contig_position = map(lambda x: (*x[-1], x[0]), enumerate(remove_none, start=1))\n",
    "    return tuple(add_on_contig_position)\n",
    "\n",
    "\n",
    "cluster_assignments = mmseqs_to_dict('/home/hugo/projects/icetea/results/mmseqs/CLUSTERS_REPS_unique.tsv')\n",
    "\n",
    "all_cds = parse_merged_gff('/home/hugo/projects/icetea/results/gff/all.cds.gff.sample.out')\n",
    "\n",
    "add_cluster_assignments = map(lambda x: (*x[:-1], cluster_assignments.get(x[-1])), all_cds)\n",
    "\n",
    "get_contigs = defaultdict(list)\n",
    "\n",
    "for i in add_cluster_assignments:\n",
    "    get_contigs[i[:-1]].append(i[-1])\n",
    "\n",
    "get_contigs = {k: get_edges(v) for k, v in get_contigs.items()}\n",
    "\n",
    "edges =  defaultdict(list)\n",
    "\n",
    "for k, v in get_contigs.items():\n",
    "    for edge in v:\n",
    "        edges[edge[:-1]].append((*k, edge[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Add edges and attributes\n",
    "G.add_edges_from(map(lambda x: (*x[0], {'info' : tuple(x[1])}), edges.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native\n",
    "from typing import Generator\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "# third party\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# read networkx graph from file pickle\n",
    "with open('/home/hugo/projects/icetea/results/salmonella.pickle', 'rb') as f:\n",
    "    G = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>closest_nodes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <th>componet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DS1</th>\n",
       "      <th>1</th>\n",
       "      <td>{HCKDJKIF_02548}</td>\n",
       "      <td>{IDNFEDEF_04437, EEPIDGAD_04500, DHBDDKCN_0024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{OECGJKMM_02137}</td>\n",
       "      <td>{EEPIDGAD_04500, JADHFFOP_00313, AHGJPDMF_0452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{HAOCBECO_02921}</td>\n",
       "      <td>{HIFGEHPB_00061, ADHBLBMG_00779, OBBFEPPO_0473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DS4</th>\n",
       "      <th>1</th>\n",
       "      <td>{PLOGOCIG_03756}</td>\n",
       "      <td>{EEPIDGAD_04500, CBHEPBDH_04236, IKHNHLMK_0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{PGPIBDBP_02126}</td>\n",
       "      <td>{IDNFEDEF_04437, EEPIDGAD_04500, DHBDDKCN_0024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          cluster  \\\n",
       "system componet                     \n",
       "DS1    1         {HCKDJKIF_02548}   \n",
       "       2         {OECGJKMM_02137}   \n",
       "       3         {HAOCBECO_02921}   \n",
       "DS4    1         {PLOGOCIG_03756}   \n",
       "       2         {PGPIBDBP_02126}   \n",
       "\n",
       "                                                     closest_nodes  \n",
       "system componet                                                     \n",
       "DS1    1         {IDNFEDEF_04437, EEPIDGAD_04500, DHBDDKCN_0024...  \n",
       "       2         {EEPIDGAD_04500, JADHFFOP_00313, AHGJPDMF_0452...  \n",
       "       3         {HIFGEHPB_00061, ADHBLBMG_00779, OBBFEPPO_0473...  \n",
       "DS4    1         {EEPIDGAD_04500, CBHEPBDH_04236, IKHNHLMK_0037...  \n",
       "       2         {IDNFEDEF_04437, EEPIDGAD_04500, DHBDDKCN_0024...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "def read_mmseqs_search_output(\n",
    "    fn: str, usecols: str = \"query,target,pident,qcov,tcov\"\n",
    ") -> pd.DataFrame:\n",
    "    header = \"query,target,pident,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits,qcov,tcov\".split(\n",
    "        \",\"\n",
    "    )\n",
    "    return pd.read_csv(\n",
    "        fn,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=header,\n",
    "        usecols=usecols.split(\",\"),\n",
    "    )\n",
    "\n",
    "def query_network(G: nx.Graph, query_node: str, radius: int) -> set:\n",
    "    try:\n",
    "        return set(nx.ego_graph(G, query_node, radius=radius).nodes())\n",
    "    except nx.exception.NodeNotFound:\n",
    "        return set()\n",
    "    \n",
    "query_radius = 5\n",
    "query_network_preloaded = partial(query_network, G, radius=query_radius)\n",
    "\n",
    "\n",
    "systems_matches = (\n",
    "    read_mmseqs_search_output('/home/hugo/projects/icetea/results/mmseqs/New-DS-V2_X_SALMONELLA_REPS.search.tsv')\n",
    "    .loc[lambda df_: df_['query'].str.startswith(('DS1', 'DS4')), ['query', 'target']]\n",
    "    .pipe(\n",
    "        lambda df_: pd.DataFrame(\n",
    "            data=df_.target.values,\n",
    "            columns=['cluster'],\n",
    "            index=pd.MultiIndex.from_arrays(df_['query'].str.split('-', expand=True).values.T, names=['system', 'componet']),\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        closest_nodes = lambda df_: df_.cluster.apply(query_network_preloaded)\n",
    "    )\n",
    "    .groupby(['system', 'componet'])\n",
    "    .agg(\n",
    "        {\n",
    "            \"cluster\": set,\n",
    "            \"closest_nodes\": lambda s_: set(chain.from_iterable(s_)),\n",
    "        }\n",
    "    )\n",
    "    .loc[lambda df_: df_.closest_nodes.apply(bool)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "systems_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, system_df in systems_matches.groupby(\"system\"):\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Generator\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_edge_info(G: nx.Graph) -> Generator[Tuple[str, str, List[Tuple[int, str, str]]], None, None]:\n",
    "    contigs = defaultdict(list)\n",
    "\n",
    "    for i in G.edges(data=True):\n",
    "        source, target, attributes = i\n",
    "        for i in attributes['info']:\n",
    "            assembly, contig, oncontig_pos = i\n",
    "            contigs[(assembly, contig)].append((source, target, oncontig_pos))\n",
    "\n",
    "    yield from ((*k, tuple(sorted(v, key=lambda x: x[-1]))) for k, v in contigs.items())\n",
    "\n",
    "def get_windows(t):\n",
    "    windows = []\n",
    "    current_window = 1\n",
    "    for i in range(len(t)):\n",
    "        if i == 0:\n",
    "            windows.append(current_window)\n",
    "            continue\n",
    "        if t[i] - t[i-1] == 1:\n",
    "            windows.append(current_window)\n",
    "        else:\n",
    "            current_window += 1\n",
    "            windows.append(current_window)\n",
    "    return tuple(windows)\n",
    "\n",
    "def edge_info_to_df(t):\n",
    "    assembly, contig, edge_info = t\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            data=edge_info,\n",
    "            columns=['source', 'target', 'oncontig_pos'],\n",
    "        )\n",
    "        .assign(\n",
    "            window = lambda df_: df_.oncontig_pos.diff().ne(1).cumsum(),\n",
    "            assembly = assembly,\n",
    "            contig = contig,\n",
    "        )\n",
    "        .groupby(['assembly', 'contig', 'window'])\n",
    "        # join the source and target nodes into a set\n",
    "        .agg(\n",
    "            {\n",
    "                'source': set,\n",
    "                'target': set,\n",
    "            }\n",
    "        )           \n",
    "            \n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "def get_freq_from_sytem(system_df: pd.DataFrame, main_graph: nx.Graph,) -> pd.DataFrame:\n",
    "    system_G = main_graph.subgraph(set(chain.from_iterable(system_df.closest_nodes)))\n",
    "\n",
    "    system_clusters = set(chain.from_iterable(system_df.cluster))\n",
    "\n",
    "    all_edge_info = extract_edge_info(system_G)\n",
    "\n",
    "    contigs_with_matches = filter(\n",
    "        lambda tup: (\n",
    "            any(cluster in system_clusters for cluster in chain.from_iterable(info_tupe[:-1] for info_tupe in tup[-1]))\n",
    "        ),\n",
    "        all_edge_info\n",
    "    )\n",
    "\n",
    "    to_df = map(edge_info_to_df, contigs_with_matches)\n",
    "\n",
    "    for i in to_df:\n",
    "        print(i.sort_index())\n",
    "        return\n",
    "\n",
    "\n",
    "get_freq_from_sytem(system_df, G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JFGHGAKM_04203 LBGIAHIP_00357\n",
      "('59201.294', '77', 204)\n",
      "('59201.294', '77', (('JFGHGAKM_04203', 'LBGIAHIP_00357', 204),))\n"
     ]
    }
   ],
   "source": [
    "genomes = defaultdict(list)\n",
    "\n",
    "for i in G.edges(data=True):\n",
    "    source, target, attributes = i\n",
    "    print(source, target)\n",
    "    for i in attributes['info']:\n",
    "        print(i)\n",
    "        assembly, contig, oncontig_pos = i\n",
    "        genomes[(assembly, contig)].append((source, target, oncontig_pos))\n",
    "        break\n",
    "    break\n",
    "\n",
    "def test(d):\n",
    "    yield from ((*k, tuple(sorted(v, key=lambda x: x[-1]))) for k, v in d.items())\n",
    "\n",
    "\n",
    "for i in test(genomes):\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 2, 2, 3)\n",
      "(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "()\n",
      "(1, 2, 3, 4, 4, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# doing this: windows=lambda df_: df_.on_contig_position.diff().ne(1).cumsum(). But in python\n",
    "# input : t = (1,2,3,5,6,10)\n",
    "# output: (1,1,1,2,2,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test input\n",
    "t = [\n",
    "    (1,2,3,5,6,10),\n",
    "    (1,2,3,4,5,6,7,8,9,10),\n",
    "    (),\n",
    "    (1,3,5,7,8,9,10),\n",
    "]\n",
    "\n",
    "\n",
    "for i in t:\n",
    "    print(get_windows(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system  componet\n",
       "DS1     1           56743\n",
       "        2           13324\n",
       "        3            1705\n",
       "DS4     1           40026\n",
       "        2           61023\n",
       "Name: closest_nodes, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systems_matches.closest_nodes.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_merged_gff(fn: str):\n",
    "    \"\"\" Parses a merged gff file and returns a generator of tuples \"\"\"\n",
    "        \n",
    "\n",
    "        while (line := next(lines, None)):\n",
    "            if line.startswith('#!genome-build-accession NCBI_Assembly:'):\n",
    "                assembly = line.split(':')[-1]\n",
    "                contigs = defaultdict(list)\n",
    "                continue\n",
    "\n",
    "            if line.startswith('###'):\n",
    "                contigs = dict(map(lambda x: (x[0], tuple(x[1])), contigs.items()))\n",
    "                yield (assembly, contigs)\n",
    "                continue\n",
    "\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            contig, *_, info = line.split('\\t')\n",
    "\n",
    "            if (protein_id := get_protein_id_from_gff_info(info)): #### <-- Walrus operator\n",
    "                contigs[contig].append(protein_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polars_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb6ffa45c82960c8bd96630701e1863d66e80dc612d3f0c1bf1c246e54b3d4ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
